{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### `---------------Mandatory Information to fill------------`"],"metadata":{"id":"j7jO_ata_tGB"}},{"cell_type":"markdown","metadata":{"id":"q5BJ7jLz7afs"},"source":["### Group ID:\n","### Group Members Name with Student ID:\n","1. Student 1\n","2. Student 2\n","3. Student 3\n","4. Student 4\n"]},{"cell_type":"markdown","source":["`-------------------Write your remarks (if any) that you want should get consider at the time of evaluation---------------`"],"metadata":{"id":"YXHhoNgkAhUg"}},{"cell_type":"markdown","source":["Remarks: ##Add here"],"metadata":{"id":"-5tK16CbA5X_"}},{"cell_type":"markdown","source":["# Scenario\n","\n","A pharmaceutical company is conducting clinical trials to evaluate the effectiveness of three antiretroviral drug combinations for treating HIV-positive patients. Due to the ethical and cost constraints of clinical trials, it is critical to identify the most effective treatment regimen using the least number of patients. Each treatment (or “arm”) can lead to different outcomes depending on patient responses. The effectiveness of each treatment is evaluated using a reward function derived from the improvement in patients’ immune system markers and survival status.\n","\n"],"metadata":{"id":"z8nESwkOIE_u"}},{"cell_type":"markdown","source":["# Problem Definition\n","\n","You are provided with a clinical dataset where each record corresponds to a patient, including the treatment they received and the resulting health outcomes. Your task is to simulate a clinical trial environment using various MAB strategies to sequentially recommend treatments and observe outcomes. The objective is to maximize the overall success rate across trials by identifying and favouring the most effective treatment.\n","\n"],"metadata":{"id":"I8w5a_8g-ehV"}},{"cell_type":"markdown","source":["# Dataset\n","\n","You will be provided a dataset containing the following fields:\n","\n","* ***Age (age)***: Patient's age in years at baseline.\n","* ***Weight (wtkg)***: Continuous feature representing weight in kilograms at baseline.\n","* ***Gender (gender)***: Binary indicator of gender (0 = Female, 1 = Male).\n","* ***CD4 Counts (cd40, cd420)***: Integer values representing CD4 counts at baseline and 20+/-5 weeks.\n","* ***Treatment Indicator (trt)***: Categorical feature indicating the type of treatment received (0 = ZDV only, 1 = ZDV + ddI, 2 = ZDV + Zal, 3 = ddI only).\n","* ***Censoring Indicator (label)***: Binary indicator (1 = failure, 0 = censoring) denoting patient status.\n","\n","\n","***Link for accessing dataset:***\n","https://drive.google.com/file/d/1LYfIrJ4VEEGeyOsSt_qoLk7FaAv5Jfx-/view?usp=sharing\n"],"metadata":{"id":"0v1QvKmDIVoe"}},{"cell_type":"markdown","source":["# Environment Setup\n","\n","***Arms (Actions):*** The treatment types (trt)\n","* Arm 0: ZDV only\n","* Arm 1: ZDV + ddI\n","* Arm 2: ZDV + Zal\n","* Arm 3: ddI only\n","\n","\n","**Reward Function:**\n","\n","Reward `r` is defined as:\n","\n","`r = 1, if (label == 0) and (cd420 > cd40)`\n","\n","`r = 0, otherwise`\n","\n","\n","  \n","This reward represents a successful treatment outcome as an increase in CD4 count and survival.\n","\n","**Assumptions:**\n","\n","*Number of Iterations:* Run the simulation for at least 1000 trials (iterations), with the option to extend the number of trials depending on the convergence behavior or observed reward trends. In each iteration, simulate one patient trial using one of the bandit policies.\n"],"metadata":{"id":"53dVBXmoL8aF"}},{"cell_type":"markdown","source":["# Requirements and Deliverables:\n","Implement the Multi-Arm Bandit Problem for the given above scenario for all the below mentioned policy methods."],"metadata":{"id":"Z0whadvHOywr"}},{"cell_type":"markdown","source":["### Initialize constants"],"metadata":{"id":"Pck-piUAHnmp"}},{"cell_type":"code","source":["# Constants\n"],"metadata":{"id":"dgeqZVzXHlQE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Dataset (0.5M)"],"metadata":{"id":"Ke_jHsCrQWG0"}},{"cell_type":"code","source":["# Code for Dataset loading and print dataset statistics\n","#-----write your code below this line---------\n","\n"],"metadata":{"id":"FSlqMVeEQa4T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Design a Clinical Trial Environment (0.5M)"],"metadata":{"id":"HroEzPwhQkwq"}},{"cell_type":"code","source":["# Code for environment setup along with reward function\n","#-----write your code below this line---------\n","\n","class ClinicalTrialEnvironment:\n"],"metadata":{"id":"Uc7EP7ZXQsn5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using Random Policy (0.5M)\n","Implement a random policy for treatment selection and print each 100th iteration. (Mandatory)"],"metadata":{"id":"Hvbd8vPwRMBL"}},{"cell_type":"code","source":["#  run the environment with an agent that is guided by a random policy\n","#-----write your code below this line---------"],"metadata":{"id":"99WQfj3eROWc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using Greedy Policy (1M)\n","Implement the Greedy policy that always selects the treatment with the highest average reward and print each 100th iteration. (Mandatory)"],"metadata":{"id":"5t2f1AlERib1"}},{"cell_type":"code","source":["#  run the environment with an agent that is guided by a greedy policy\n","#-----write your code below this line---------"],"metadata":{"id":"TbWz1eCbRib2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using Epsilon-Greedy Policy (1.5M)\n","Implement the ε-Greedy policy with ε = 0.1, 0.2, 0.5. Report iteration-wise selections and rewards. Determine which ε yields the best result. (Mandatory)"],"metadata":{"id":"h65VF2JBRiph"}},{"cell_type":"code","source":["#  run the environment with an agent that is guided by a epsilon-greedy policy\n","#-----write your code below this line---------"],"metadata":{"id":"M6O9odmlRiph"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using UCB (1M)\n","Implement the UCB algorithm for treatment selection and print each 100th iteration. (Mandatory)"],"metadata":{"id":"yRo-Wi17RiN2"}},{"cell_type":"code","source":["#  run the environment with an agent that is guided by a UCB\n","#-----write your code below this line---------"],"metadata":{"id":"Z8nXetCeRiN8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Plot the cumulative rewards for all policies on a single graph to compare their performance. (0.5M)"],"metadata":{"id":"y9QjCw5aIrBn"}},{"cell_type":"code","source":["#-----write your code below this line---------"],"metadata":{"id":"J_5XxqPZI2uW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conclusion (0.5M)\n","\n","write a conclusion (approximately 250 words) summarizing which treatment policy was most effective. Discuss the balance between exploration and exploitation in your simulations.\n","\n","`----write below this line------`"],"metadata":{"id":"xOQk0LcUImEW"}},{"cell_type":"code","source":[],"metadata":{"id":"jcdGV9-cIqli"},"execution_count":null,"outputs":[]}]}